{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6c6c0-0edc-467c-a6c2-8113dbf4c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet langchain-anthropic langchain-neo4j cyVer langchain-google-genai json-repair \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36fa35-f5b9-483a-8d3f-93deae83a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from utils import (\n",
    "    _value_sanitize,\n",
    "    extract_json_from_markdown,\n",
    "    sampling_query,\n",
    "    validate_cypher,\n",
    "    process_database,\n",
    "    process_all_examples_with_limit,\n",
    "    convert_datetime\n",
    ")\n",
    "from prompts import (\n",
    "    system_prompt,\n",
    "    simple_system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b8449-ca9a-4e0d-81a6-e70282af7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\"run.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c960d-62b6-4020-91f8-9fb7df14d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Db Name, Login, Pwd, URI]\n",
    "DATABASES=json.loads(config.get('DATABASES'))\n",
    "# [LLM Name, Model], can be GOOGLE, CLAUDE\n",
    "LLM_CREATES=json.loads(config.get('LLM_CREATES'))\n",
    "# GOOGLE, CLAUDE\n",
    "LLM_QA=config.get('LLM_QA')\n",
    "LLM_QA_MODEL=config.get('LLM_QA_MODEL')\n",
    "LLM_QA_API_KEY=config.get('LLM_QA_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb8a21e-12fe-47b7-9895-6648b42045a5",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfc7f0-86fb-424e-8a41-1a2eb4677dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM selection\n",
    "models = []\n",
    "for l in LLM_CREATES:\n",
    "    if l[0] == 'CLAUDE':\n",
    "        os.environ[\"ANTHROPIC_API_KEY\"] = l[2]\n",
    "        models.append(ChatAnthropic(model=l[1]))\n",
    "    elif l[0] == 'GOOGLE':\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = l[2]\n",
    "        models.append(ChatGoogleGenerativeAI(model=l[1]))\n",
    "    else:\n",
    "        print(\"Incorrect LLM provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474866e2-b4a9-4b98-962d-11754df7fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_batch_count = 1 # Number of iterations for simple queries\n",
    "multi_batch_count = 1 # Number of iterations complex queries\n",
    "\n",
    "output = []\n",
    "\n",
    "for model in models:\n",
    "    print(model.model)\n",
    "    for database in tqdm(DATABASES, desc=\"Processing databases\"):\n",
    "        # Simple question\n",
    "        database_records = process_database(\n",
    "            database, model, simple_batch_count, simple_system_prompt\n",
    "        )\n",
    "        output.extend(database_records)\n",
    "\n",
    "        database_records = process_database(\n",
    "            database, model, multi_batch_count, system_prompt\n",
    "        )\n",
    "        output.extend(database_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912281c-de2a-46b7-983e-9bd8eea21a73",
   "metadata": {},
   "source": [
    "# Generate text answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d18e3c-875a-4b12-8713-b14545fab33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model = None\n",
    "\n",
    "if LLM_QA == 'CLAUDE':\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = LLM_QA_API_KEY\n",
    "    qa_model = ChatAnthropic(model=LLM_QA_MODEL)\n",
    "elif LLM_QA == 'GOOGLE':\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = LLM_QA_API_KEY\n",
    "    qa_model = ChatGoogleGenerativeAI(model=LLM_QA_MODEL)\n",
    "else:\n",
    "    print(\"No LLM provided for generating the text answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70df72-0765-4b13-8c5e-9f171b6f70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = [el for el in output if el[\"validated\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe6727-7ee2-405d-b02a-cfe9977b9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd5b0b-358c-4fda-9c90-72a835f0a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text-based answers\n",
    "await process_all_examples_with_limit(validated, qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4a539-b6ce-4f52-8964-4ef93a0600dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the question cannot be answered, remove record\n",
    "validated = [el for el in validated if not \"UNKNOWN\" in el['answer']]\n",
    "\n",
    "df = pd.DataFrame.from_records(validated)\n",
    "print(f\"Total QA pairs: {len(df)}\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938bb90-115c-4060-ba5e-d1bbbb61e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'output' is defined elsewhere in your code\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(timestr)\n",
    "with open(f\"generated_dataset_{timestr}.json\", \"w\") as f:\n",
    "    json.dump(validated, f, indent=2, default=convert_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a0ce3-6f5e-4b6e-865d-c8afb34c5045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
